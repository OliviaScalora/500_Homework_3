View(Cross_Agg)
View(mydata)
# MAKING IT PRETTY
finallogitoutput%>%kable(format = "html", align = "rlllllll", caption = "Logistic Regression Results")%>%
kable_paper("hover")%>%kable_styling(full_width=F)
CrossTable[, c(3,7,1,5,2,6,4,8)]%>%
kable(col.names = c("Variable", "","N","%","N","%","N", "Chi-Square\np-value"),
align = c('r','l','c','c','c','c','c','c'),
caption = 'Table 2')%>%
kable_paper()%>%
add_header_above(c("","","No Alcohol Involved\n(Drinkind_D = 0)" = 2, "Alcohol Involved\n(Drinkind_D = 1)" = 2,"Total", ""),
align = c('r','c'))%>%
kable_styling( bootstrap_options = "hover")%>%
column_spec(1,bold = TRUE)%>%
column_spec(5,border_left = TRUE)%>%
column_spec(c(3:4),background = '#f1f1f1')%>%
column_spec(c(5:6),background = '#e1e1e1')
#Here, we're saying that a high probability of there being a hospital in a
#zip code is >= 0.1, and a low probability of there being a hospital in a
#zip code is <0.1. In the cross-tabulation, true corresponds to high probability
#and false corresponds to low probability.
#We will then go on to calculate the sensitivity, specificity, and misclassification
#rate for the cut-off of 0.1
fit.binary = (fit>=0.1)
CrossTable(fit.binary, mydata$Hospital, prop.r=FALSE, prop.t=FALSE, prop.c=FALSE, prop.chisq=FALSE)
#Here, we're saying that a high probability of there being a hospital in a
#zip code is >= 0.1, and a low probability of there being a hospital in a
#zip code is <0.1. In the cross-tabulation, true corresponds to high probability
#and false corresponds to low probability.
#We will then go on to calculate the sensitivity, specificity, and misclassification
#rate for the cut-off of 0.1
ex.data<- read.csv('C:\\Users\\oscal\\Downloads\\Logistic Regression Example.csv')
fit.binary = (fit>=0.1)
CrossTable(fit.binary, ex.data$Hospital, prop.r=FALSE, prop.t=FALSE, prop.c=FALSE, prop.chisq=FALSE)
View(ex.data)
CrossTable(fit.binary, ex.data$Hospital, prop.r=FALSE, prop.t=FALSE, prop.c=FALSE, prop.chisq=FALSE)
#Doing everything we did above, except now the cut-offs are 0.2, 0.3, 0.4, 0.5,
#0.6, 0.7, 0.8, and 0.9.
fit.binary = (fit>=0.2)
CrossTable(fit.binary, mydata$Hospital, prop.r=FALSE, prop.t=FALSE, prop.c=FALSE, prop.chisq=FALSE)
View(ex.data)
fit.binary = (fit>=0.1)
CrossTable(fit.binary, ex.data$Hospital, prop.r=FALSE, prop.t=FALSE, prop.c=FALSE, prop.chisq=FALSE)
source("C:/Users/oscal/Downloads/Calculating Sensitivity and Specificity for Various Probability Cut-Offs.R", echo=TRUE)
fit.binary = (fit>=0.1)
View(iterateThresholds)
View(opt.cut)
ind = which(d == min(d))
cut.ind = mapply(FUN=function(x, y, p){
d = (x - 0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
cutoff = p[[ind]])
}
cut.ind = mapply(FUN=function(x, y, p){
d = (x - 0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
cutoff = p[[ind]])
})
cut.ind = mapply(FUN=function(x, y, p){
d = (x - 0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
cutoff = p[[ind]])
})
cut.ind = {
d = (x - 0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
cutoff = p[[ind]])
}
cut.ind = function(x, y, p){
d = (x - 0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
cutoff = p[[ind]])
}
cut.ind(roc.perf, pred)
opt.cut(roc.perf, pred)
opt.cut(roc.perf, pred)
opt.cut = function(perf, pred){
cut.ind = mapply(FUN=function(x, y, p){
d = (x - 0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
cutoff = p[[ind]])
}, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(roc.perf, pred))
cut.ind = mapply(FUN=function(x, y, p){
d = (x - 0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
cutoff = p[[ind]])
})
View(cut.ind)
cut.ind = function(per, pred){mapply(FUN=function(x, y, p){
d = (x - 0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
cutoff = p[[ind]])
})}
cut.ind (roc.perf, pred)
cut.ind(roc.perf, pred)
print(cut.ind(roc.perf, pred))
lol <- cut.ind(roc.perf, pred)
View(lol)
opt.cut2 = function(perf, pred){
cut.ind = mapply(FUN=function(x, y, p){
print(x)
print(y)
d = (x - 0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
cutoff = p[[ind]])
}, perf@x.values, perf@y.values, pred@cutoffs)
}
opt.cut2(roc.perf, pred)
opt.cut2 = function(perf, pred){
cut.ind = mapply(FUN=function(x, y, p){
print(x)
d = (x - 0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
cutoff = p[[ind]])
}, perf@x.values, perf@y.values, pred@cutoffs)
}
opt.cut2(roc.perf, pred)
View(roc.perf)
print(opt.cut(roc.perf, pred))
ourthresh%>%kable(format = "html", align = "llll", caption = "Goodness of Fit Metrics",
col.names = c("Cut Off Value", "Sensitivity", "Specificity", "Missclassification Rate"))%>%
kable_material("hover")%>%kable_styling(full_width=F)%>%
row_spec(10, bold = T,background = "#f0d560")
ourthresh%>%kable(format = "html", align = "llll", caption = "Goodness of Fit Metrics",
col.names = c("Cut Off Value", "Sensitivity", "Specificity", "Missclassification Rate"))%>%
kable_material("hover")%>%kable_styling(full_width=F)%>%
row_spec(10, bold = T,background = "#f0d560")
#library(packagename)
library(aod)
library(ggplot2)
library(rms)
library(gmodels)
library(boot)
library(DAAG)
library(ROCR)
library(tidyr)
library(dplyr)
library(MASS)
library(rsq)
library(kableExtra)
library(tidyverse) #for ggplot
#library(sf) #for maps
#library(cowplot) #for plotgrid
library(classInt)#for jenks breaks
library(rgdal)
library(RColorBrewer)
library(broom)
library(maptools)
library(spdep)
library(spgwr)
library(rgeos)
library(ape)
library(tmap)
library(sp)
library(spatialreg)
library(kableExtra)
library(knitr)
#install.packages('DT')
library(DT)
ourthresh%>%kable(format = "html", align = "llll", caption = "Goodness of Fit Metrics",
col.names = c("Cut Off Value", "Sensitivity", "Specificity", "Missclassification Rate"))%>%
kable_material("hover")%>%kable_styling(full_width=F)%>%
row_spec(10, bold = T,background = "#f0d560")
a <- cbind(mydata$DRINKING_D, fit)
#b is matrix a, just sorted by the variable fit
b <- a[order(a[,2]),]
b=as.data.frame(b)
colnames(b) <- c("Observed.DRINKING_D","Probability.DRINKING_D")
c <- (b[,2] >= 0.05)
d <- cbind(b,c)
#Let's label the columns of matrix d for easier reading
colnames(d) <- c("Observed.DRINKING_D","Probability.DRINKING_D","Prob.Above.Cutoff")
View(d)
#Other cut-offs can be used here!
c02 <- (b[,2] == 0.02)
#Creating matrix d which merges matrixes b and c
d <- cbind(b,c02)
#Let's label the columns of matrix d for easier reading
colnames(d) <- c("Observed.DRINKING_D","Probability.DRINKING_D","Prob.Above.Cutoff")
#Other cut-offs can be used here!
c <- (b[,2] == 0.02 | b[,2] == 0.03|b[,2] == 0.05|(b[,2] > 0.06 & b[,2] < 0.11)| b[,2] == 0.15 | b[,2] == 0.2 | b[,2] == 0.5)
#Creating matrix d which merges matrixes b and c
d <- cbind(b,c)
#Let's label the columns of matrix d for easier reading
colnames(d) <- c("Observed.DRINKING_D","Probability.DRINKING_D","Prob.Above.Cutoff")
#Converting matrix to data frame
e=as.data.frame(d)
e%>%kable()%>%kable_material_dark()
#Cross-tabulation
CrossTable(e$Prob.Above.Cutoff, e$Observed.DRINKING_D, prop.r=FALSE,prop.chisq=FALSE, chisq=FALSE,prop.t=FALSE)
#Converting matrix to data frame
e=as.data.frame(d)
ourthresh%>%kable(format = "html", align = "llll", caption = "Goodness of Fit Metrics",
col.names = c("Cut Off Value", "Sensitivity", "Specificity", "Missclassification Rate"))%>%
kable_material("hover")%>%kable_styling(full_width=F)%>%
row_spec(10, bold = T,background = "#f0d560")
View(e)
e=e%>%dplyr::mutate(0.02 = ifelse(Probability.DRINKING_D >= 0.02, 1, 0),
0.03 = ifelse(Probability.DRINKING_D >= 0.03, 1, 0),
0.05 = ifelse(Probability.DRINKING_D >= 0.05, 1, 0),
0.07 = ifelse(Probability.DRINKING_D >= 0.07, 1, 0),
0.08 = ifelse(Probability.DRINKING_D >= 0.08, 1, 0),
0.09 = ifelse(Probability.DRINKING_D >= 0.09, 1, 0),
0.10 = ifelse(Probability.DRINKING_D >= 0.10, 1, 0),
0.15 = ifelse(Probability.DRINKING_D >= 0.15, 1, 0),
0.20 = ifelse(Probability.DRINKING_D >= 0.20, 1, 0),
0.50 = ifelse(Probability.DRINKING_D >= 0.50, 1, 0))
e=e%>%dplyr::mutate(0.02 = ifelse(Probability.DRINKING_D >= 0.02, 1, 0))
e<-e%>%dplyr::mutate(0.02 = ifelse(Probability.DRINKING_D >= 0.02, 1, 0))
e<-e%>%dplyr::mutate(0.02 = if else(Probability.DRINKING_D >= 0.02, 1, 0))
e<-e%>%dplyr::mutate("0.02" = if else(Probability.DRINKING_D >= 0.02, 1, 0))
e<-e%>%dplyr::mutate("0.02" = ifelse(Probability.DRINKING_D >= 0.02, 1, 0))
e<-e%>%dplyr::mutate("0.02" = ifelse(Probability.DRINKING_D >= 0.02, 1, 0),
"0.03" = ifelse(Probability.DRINKING_D >= 0.03, 1, 0),
"0.05" = ifelse(Probability.DRINKING_D >= 0.05, 1, 0),
"0.07" = ifelse(Probability.DRINKING_D >= 0.07, 1, 0),
"0.08" = ifelse(Probability.DRINKING_D >= 0.08, 1, 0),
'0.09' = ifelse(Probability.DRINKING_D >= 0.09, 1, 0),
'0.10' = ifelse(Probability.DRINKING_D >= 0.10, 1, 0),
'0.15' = ifelse(Probability.DRINKING_D >= 0.15, 1, 0),
'0.20'= ifelse(Probability.DRINKING_D >= 0.20, 1, 0),
'0.50' = ifelse(Probability.DRINKING_D >= 0.50, 1, 0))
TP <- e%>%summarize(Count_TN = sum(n["0.02"==0 & !!"Observed.DRINKING_D"==0]),
Count_TP = sum(n["0.02"==1 & !!"Observed.DRINKING_D"==1]),
Count_FN = sum(n["0.02"==0 & !!"Observed.DRINKING_D"==1]),
Count_FP = sum(n["0.02"==1 & !!"Observed.DRINKING_D"==0]))
TP <- e%>%summarize(Count_TN = sum(n("0.02"==0 & !!"Observed.DRINKING_D"==0)))
TP <- e%>%mutate(Count_TN = sum(n("0.02"==0 & !!"Observed.DRINKING_D"==0)))
e<-e%>%dplyr::mutate("f0.02" = ifelse(Probability.DRINKING_D >= 0.02, 1, 0),
"0.03" = ifelse(Probability.DRINKING_D >= 0.03, 1, 0),
"0.05" = ifelse(Probability.DRINKING_D >= 0.05, 1, 0),
"0.07" = ifelse(Probability.DRINKING_D >= 0.07, 1, 0),
"0.08" = ifelse(Probability.DRINKING_D >= 0.08, 1, 0),
'0.09' = ifelse(Probability.DRINKING_D >= 0.09, 1, 0),
'0.10' = ifelse(Probability.DRINKING_D >= 0.10, 1, 0),
'0.15' = ifelse(Probability.DRINKING_D >= 0.15, 1, 0),
'0.20'= ifelse(Probability.DRINKING_D >= 0.20, 1, 0),
'0.50' = ifelse(Probability.DRINKING_D >= 0.50, 1, 0))
TP <- e%>%mutate(Count_TN = sum(n("f0.02"==0 & !!"Observed.DRINKING_D"==0)))
TP <- e%>%mutate(Count_TN = sum(n["f0.02"==0 & !!"Observed.DRINKING_D"==0]))
c2<-(b[,2] == 0.02)
#Creating matrix d which merges matrixes b and c
d2 <- cbind(b,c2)
c2<-(b[,2] == 0.02)
c3<-(b[,2] == 0.07)
#Creating matrix d which merges matrixes b and c
d2 <- cbind(b,c2)
d3 <- cbind(b,c3)
#Let's label the columns of matrix d for easier reading
colnames(d2) <- c("Observed.DRINKING_D","Probability.DRINKING_D","Prob.Above.Cutoff")
#Let's label the columns of matrix d for easier reading
colnames(d3) <- c("Observed.DRINKING_D","Probability.DRINKING_D","Prob.Above.Cutoff")
#Converting matrix to data frame
e2=as.data.frame(d2)
#Converting matrix to data frame
e3=as.data.frame(d3)
#Cross-tabulation
CrossTable(e2$Prob.Above.Cutoff, e$Observed.DRINKING_D, prop.r=FALSE,prop.chisq=FALSE, chisq=FALSE,prop.t=FALSE)
#Cross-tabulation
CrossTable(e3$Prob.Above.Cutoff, e$Observed.DRINKING_D, prop.r=FALSE,prop.chisq=FALSE, chisq=FALSE,prop.t=FALSE)
a <- cbind(mydata$DRINKING_D, fit)
#b is matrix a, just sorted by the variable fit
b <- a[order(a[,2]),]
#Other cut-offs can be used here!
c <- (b[,2] >= 0.02)
#Other cut-offs can be used here!
c <- (b[,2] >= 0.07)
#Creating matrix d which merges matrixes b and c
d <- cbind(b,c)
#Let's label the columns of matrix d for easier reading
colnames(d) <- c("Observed.DRINKING_D","Probability.DRINKING_D","Prob.Above.Cutoff")
#Converting matrix to data frame
e=as.data.frame(d)
#Cross-tabulation
CrossTable(e$Prob.Above.Cutoff, e$Observed.DRINKING_D, prop.r=FALSE,prop.chisq=FALSE, chisq=FALSE,prop.t=FALSE)
(550)/(550+3523)
37356/(37356+1935)
(1935+3523)/(3523+550+1935+37356)
#Other cut-offs can be used here!
c <- (b[,2] >= 0.05)
#Creating matrix d which merges matrixes b and c
d <- cbind(b,c)
#Let's label the columns of matrix d for easier reading
colnames(d) <- c("Observed.DRINKING_D","Probability.DRINKING_D","Prob.Above.Cutoff")
#Converting matrix to data frame
e=as.data.frame(d)
#Cross-tabulation
CrossTable(e$Prob.Above.Cutoff, e$Observed.DRINKING_D, prop.r=FALSE,prop.chisq=FALSE, chisq=FALSE,prop.t=FALSE)
(1826)/(1826+21703)
(19176)/(19176+659)
(21703+659)/(21703+659+1826+19176)
b <- a[order(a[,2]),]
b=as.data.frame(b)
colnames(b) <- c("Observed.DRINKING_D","Probability.DRINKING_D")
whichThreshold <-
iterateThresholds(
data=b, observedClass = Observed.DRINKING_D, predictedProbs = Probability.DRINKING_D)
ourthresh <- whichThreshold %>%filter(Threshold == 0.02 | Threshold == 0.03|Threshold == 0.05|(Threshold > 0.06 & Threshold < 0.11)| Threshold == 0.15 | Threshold == 0.2 | Threshold == 0.5)%>%
dplyr::select(Threshold, Sensitivity, Specificity, MissClass_Rate)
ourthresh%>%kable(format = "html", align = "llll", caption = "Goodness of Fit Metrics",
col.names = c("Cut Off Value", "Sensitivity", "Specificity", "Missclassification Rate"))%>%
kable_material("hover")%>%kable_styling(full_width=F)%>%
row_spec(10, bold = T,background = "#f0d560")
#b is matrix a, just sorted by the variable fit
b <- a[order(a[,2]),]
#Other cut-offs can be used here!
c <- (b[,2] >= 0.06)
#Creating matrix d which merges matrixes b and c
d <- cbind(b,c)
#Let's label the columns of matrix d for easier reading
colnames(d) <- c("Observed.DRINKING_D","Probability.DRINKING_D","Prob.Above.Cutoff")
#Let's label the columns of matrix d for easier reading
colnames(d) <- c("Observed.DRINKING_D","Probability.DRINKING_D","Prob.Above.Cutoff")
#Converting matrix to data frame
e=as.data.frame(d)
#Cross-tabulation
CrossTable(e$Prob.Above.Cutoff, e$Observed.DRINKING_D, prop.r=FALSE,prop.chisq=FALSE, chisq=FALSE,prop.t=FALSE)
(1826)/(1826+21667)
19212/(19212+659)
(659+21667)/(659+21667+1826+19212)
print(opt.cut(roc.perf, pred))%>%kable(format = "html", align = "ll", caption = "Optimal Cutoff")%>%
kable_material("hover")%>%kable_styling(full_width=F)%>%row_spec(3, bold=TRUE, background = "#f0d560")
#Other cut-offs can be used here!
c <- (b[,2] >= 0.06365151)
#Creating matrix d which merges matrixes b and c
d <- cbind(b,c)
#b is matrix a, just sorted by the variable fit
b <- a[order(a[,2]),]
#Other cut-offs can be used here!
c <- (b[,2] >= 0.06365151)
#Creating matrix d which merges matrixes b and c
d <- cbind(b,c)
colnames(d) <- c("Observed.DRINKING_D","Probability.DRINKING_D","Prob.Above.Cutoff")
#Converting matrix to data frame
e=as.data.frame(d)
#Cross-tabulation
CrossTable(e$Prob.Above.Cutoff, e$Observed.DRINKING_D, prop.r=FALSE,prop.chisq=FALSE, chisq=FALSE,prop.t=FALSE)
(1642)/(1642+18590)
22289/(22289+843)
(843+18590)/(22289+843+18590+1642)
View(iterateThresholds)
View(whichThreshold)
iterateThresholds <- function(data, observedClass, predictedProbs, group) {
#This function takes as its inputs, a data frame with an observed binomial class (1 or 0); a vector of predicted #probabilities; and optionally a group indicator like race. It returns accuracy plus counts and rates of confusion matrix #outcomes. It's a bit verbose because of the if (missing(group)). I don't know another way to make an optional parameter.
observedClass <- enquo(observedClass)
predictedProbs <- enquo(predictedProbs)
group <- enquo(group)
x = .01
all_prediction <- data.frame()
if (missing(group)) {
while (x <= 1) {
this_prediction <- data.frame()
this_prediction <-
data %>%
mutate(predclass = ifelse(!!predictedProbs > x, 1,0)) %>%
count(predclass, !!observedClass) %>%
summarize(Count_TN = sum(n[predclass==0 & !!observedClass==0]),
Count_TP = sum(n[predclass==1 & !!observedClass==1]),
Count_FN = sum(n[predclass==0 & !!observedClass==1]),
Count_FP = sum(n[predclass==1 & !!observedClass==0]),
Rate_TP = Count_TP / (Count_TP + Count_FN),
Rate_FP = Count_FP / (Count_FP + Count_TN),
Rate_FN = Count_FN / (Count_FN + Count_TP),
Rate_TN = Count_TN / (Count_TN + Count_FP),
Sensitivity = Count_TP / (Count_TP + Count_FP),
Specificity = Count_TN / (Count_TN + Count_FN),
MissClass_Rate = (Count_FP + Count_FN)/(Count_FP + Count_FN + Count_TP + Count_TN),
Accuracy = (Count_TP + Count_TN) /
(Count_TP + Count_TN + Count_FN + Count_FP)) %>%
mutate(Threshold = round(x,2))
all_prediction <- rbind(all_prediction,this_prediction)
x <- x + .01
}
return(all_prediction)
}
else if (!missing(group)) {
while (x <= 1) {
this_prediction <- data.frame()
this_prediction <-
data %>%
mutate(predclass = ifelse(!!predictedProbs > x, 1,0)) %>%
group_by(!!group) %>%
count(predclass, !!observedClass) %>%
summarize(Count_TN = sum(n[predclass==0 & !!observedClass==0]),
Count_TP = sum(n[predclass==1 & !!observedClass==1]),
Count_FN = sum(n[predclass==0 & !!observedClass==1]),
Count_FP = sum(n[predclass==1 & !!observedClass==0]),
Rate_TP = Count_TP / (Count_TP + Count_FN),
Rate_FP = Count_FP / (Count_FP + Count_TN),
Rate_FN = Count_FN / (Count_FN + Count_TP),
Rate_TN = Count_TN / (Count_TN + Count_FP),
Sensitivity = Count_TP / (Count_TP + Count_FN),
Specificity = Count_TN / (Count_TN + Count_FP),
MissClass_Rate = (Count_FP + Count_FN)/(Count_FP + Count_FN + Count_TP + Count_TN),
Accuracy = (Count_TP + Count_TN) /
(Count_TP + Count_TN + Count_FN + Count_FP)) %>%
mutate(Threshold = round(x,2))
all_prediction <- rbind(all_prediction,this_prediction)
x <- x + .01
}
return(all_prediction)
}
}
#prepping
fit <-mylogit$fitted.values
a <- cbind(mydata$DRINKING_D, fit)
#b is matrix a, just sorted by the variable fit
b <- a[order(a[,2]),]
b=as.data.frame(b)
colnames(b) <- c("Observed.DRINKING_D","Probability.DRINKING_D")
37Sensitivity = Count_TP / (Count_TP + Count_FP),
Specificity = Count_TN / (Count_TN + Count_FN),
MissClass_Rate = (Count_FP + Count_FN)/(Count_FP + Count_FN + Count_TP + Count_TN),
# ----
whichThreshold <-
iterateThresholds(
data=b, observedClass = Observed.DRINKING_D, predictedProbs = Probability.DRINKING_D)
ourthresh <- whichThreshold %>%filter(Threshold == 0.02 | Threshold == 0.03|Threshold == 0.05|(Threshold > 0.06 & Threshold < 0.11)| Threshold == 0.15 | Threshold == 0.2 | Threshold == 0.5)%>%
dplyr::select(Threshold, Sensitivity, Specificity, MissClass_Rate)
ourthresh%>%kable(format = "html", align = "llll", caption = "Goodness of Fit Metrics",
col.names = c("Cut Off Value", "Sensitivity", "Specificity", "Missclassification Rate"))%>%
kable_material("hover")%>%kable_styling(full_width=F)%>%
row_spec(10, bold = T,background = "#f0d560")
View(opt.cut)
View(opt.cut)
View(opt.cut)
View(opt.cut)
opt.cut=  function(perf, pred){
cut.ind = mapply(FUN=function(x, y, p){
d = (x - 0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
cutoff = p[[ind]])
}, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(roc.perf, pred))%>%kable(format = "html", align = "ll", caption = "Optimal Cutoff")%>%
kable_material("hover")%>%kable_styling(full_width=F)%>%row_spec(3, bold=TRUE, background = "#f0d560")
View(whichThreshold)
iterateThresholds <- function(data, observedClass, predictedProbs, group) {
#This function takes as its inputs, a data frame with an observed binomial class (1 or 0); a vector of predicted #probabilities; and optionally a group indicator like race. It returns accuracy plus counts and rates of confusion matrix #outcomes. It's a bit verbose because of the if (missing(group)). I don't know another way to make an optional parameter.
observedClass <- enquo(observedClass)
predictedProbs <- enquo(predictedProbs)
group <- enquo(group)
x = .01
all_prediction <- data.frame()
if (missing(group)) {
while (x <= 1) {
this_prediction <- data.frame()
this_prediction <-
data %>%
mutate(predclass = ifelse(!!predictedProbs > x, 1,0)) %>%
count(predclass, !!observedClass) %>%
summarize(Count_TN = sum(n[predclass==0 & !!observedClass==0]),
Count_TP = sum(n[predclass==1 & !!observedClass==1]),
Count_FN = sum(n[predclass==0 & !!observedClass==1]),
Count_FP = sum(n[predclass==1 & !!observedClass==0]),
Rate_TP = Count_TP / (Count_TP + Count_FN),
Rate_FP = Count_FP / (Count_FP + Count_TN),
Rate_FN = Count_FN / (Count_FN + Count_TP),
Rate_TN = Count_TN / (Count_TN + Count_FP),
Sensitivity = Count_TP / (Count_TP + Count_FN),
Specificity = Count_TN / (Count_TN + Count_FP),
MissClass_Rate = (Count_FP + Count_FN)/(Count_FP + Count_FN + Count_TP + Count_TN),
Accuracy = (Count_TP + Count_TN) /
(Count_TP + Count_TN + Count_FN + Count_FP)) %>%
mutate(Threshold = round(x,2))
all_prediction <- rbind(all_prediction,this_prediction)
x <- x + .01
}
return(all_prediction)
}
else if (!missing(group)) {
while (x <= 1) {
this_prediction <- data.frame()
this_prediction <-
data %>%
mutate(predclass = ifelse(!!predictedProbs > x, 1,0)) %>%
group_by(!!group) %>%
count(predclass, !!observedClass) %>%
summarize(Count_TN = sum(n[predclass==0 & !!observedClass==0]),
Count_TP = sum(n[predclass==1 & !!observedClass==1]),
Count_FN = sum(n[predclass==0 & !!observedClass==1]),
Count_FP = sum(n[predclass==1 & !!observedClass==0]),
Rate_TP = Count_TP / (Count_TP + Count_FN),
Rate_FP = Count_FP / (Count_FP + Count_TN),
Rate_FN = Count_FN / (Count_FN + Count_TP),
Rate_TN = Count_TN / (Count_TN + Count_FP),
Sensitivity = Count_TP / (Count_TP + Count_FN),
Specificity = Count_TN / (Count_TN + Count_FP),
MissClass_Rate = (Count_FP + Count_FN)/(Count_FP + Count_FN + Count_TP + Count_TN),
Accuracy = (Count_TP + Count_TN) /
(Count_TP + Count_TN + Count_FN + Count_FP)) %>%
mutate(Threshold = round(x,2))
all_prediction <- rbind(all_prediction,this_prediction)
x <- x + .01
}
return(all_prediction)
}
}
View(iterateThresholds)
